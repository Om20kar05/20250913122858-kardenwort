{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de98c5f5",
   "metadata": {},
   "source": [
    "Отличный вопрос и очень детальный разбор! Вы абсолютно правы, слово `Open-Source-Praxisbeispiel` отсутствует, и я объясню почему.\n",
    "\n",
    "### Краткий ответ\n",
    "\n",
    "Слово `Open-Source-Praxisbeispiel` не попадает в итоговый список, потому что оно содержит дефисы (`-`). Ваш скрипт на самом начальном этапе обработки токенов отфильтровывает все слова, которые не состоят **исключительно из букв**, используя проверку `token.is_alpha`.\n",
    "\n",
    "### Детальное объяснение\n",
    "\n",
    "Давайте пошагово разберем, что происходит в скрипте:\n",
    "\n",
    "1.  **Токенизация текста**: Библиотека `spaCy` читает ваш текст и разбивает его на отдельные единицы — токены. Слово `Open-Source-Praxisbeispiel` будет распознано как один единый токен.\n",
    "\n",
    "2.  **Основной цикл обработки**: Внутри функций `process_text_v1` и `process_text_v2` есть цикл, который перебирает все токены. В самом начале этого цикла стоит ключевое условие:\n",
    "\n",
    "    ```python\n",
    "    if token.is_alpha and token.dep_ != \"svp\":\n",
    "    ```\n",
    "\n",
    "3.  **Проверка `token.is_alpha`**: Это свойство токена в `spaCy` возвращает `True` только в том случае, если токен состоит **полностью из буквенных символов**. Если в токене есть цифры, знаки препинания или, как в нашем случае, дефисы, `token.is_alpha` вернет `False`.\n",
    "\n",
    "4.  **Результат фильтрации**:\n",
    "    *   Для токена `Kapitel` -> `token.is_alpha` вернет `True`.\n",
    "    *   Для токена `Geschäftsprozessanalyse` -> `token.is_alpha` вернет `True`.\n",
    "    *   Для токена `Open-Source-Praxisbeispiel` -> `token.is_alpha` вернет **`False`**, потому что в нем есть дефисы.\n",
    "\n",
    "5.  **Итог**: Поскольку условие `if token.is_alpha` для этого слова не выполняется, весь блок кода, отвечающий за лемматизацию, проверку по словарю и, что важно, **разбор сложных слов с помощью German Compound Splitter (GCS)**, просто пропускается для этого токена.\n",
    "\n",
    "Именно поэтому отключение флага `--gcs` никак не влияет на результат: программа даже не доходит до вызова GCS для слова `Open-Source-Praxisbeispiel`. Оно отсеивается на самом первом шаге.\n",
    "\n",
    "---\n",
    "\n",
    "### Показательный тест-пример (Python Playbook)\n",
    "\n",
    "Вот код, который наглядно демонстрирует каждый этап этого процесса. Вы можете запустить его и увидеть все своими глазами.\n",
    "\n",
    "**Предварительные требования**:\n",
    "Убедитесь, что у вас установлены необходимые библиотеки.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e42130",
   "metadata": {},
   "source": [
    "```bash\n",
    "pip install spacy german-compound-splitter\n",
    "python -m spacy download de_core_news_lg\n",
    "# Также убедитесь, что у вас есть файл словаря 'german.dic' для GCS\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fde8e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ИСХОДНЫЙ ТЕКСТ ---\n",
      "▸ In Kapitel 12, »Geschäftsprozessanalyse«, wird zunächst beschrieben, was es überhaupt damit auf sich hat und welche Teilgebiete die Prozessanalyse beinhaltet. Anschließend erhalten Sie einen Überblick über die Diagrammsprache BPMN und zum Schluss eine Einführung in ERP- und CRM-Systeme mitsamt Open-Source-Praxisbeispiel.\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- Шаг 1: Анализ токенов и свойства is_alpha ---\n",
      "Токен                               | is_alpha\n",
      "----------------------------------- | ----------\n",
      "▸                                   | False\n",
      "In                                  | True\n",
      "Kapitel                             | True\n",
      "12                                  | False\n",
      "Geschäftsprozessanalyse             | True\n",
      "wird                                | True\n",
      "zunächst                            | True\n",
      "beschrieben                         | True\n",
      "was                                 | True\n",
      "es                                  | True\n",
      "überhaupt                           | True\n",
      "damit                               | True\n",
      "auf                                 | True\n",
      "sich                                | True\n",
      "hat                                 | True\n",
      "und                                 | True\n",
      "welche                              | True\n",
      "Teilgebiete                         | True\n",
      "die                                 | True\n",
      "Prozessanalyse                      | True\n",
      "beinhaltet                          | True\n",
      "Anschließend                        | True\n",
      "erhalten                            | True\n",
      "Sie                                 | True\n",
      "einen                               | True\n",
      "Überblick                           | True\n",
      "über                                | True\n",
      "die                                 | True\n",
      "Diagrammsprache                     | True\n",
      "BPMN                                | True\n",
      "und                                 | True\n",
      "zum                                 | True\n",
      "Schluss                             | True\n",
      "eine                                | True\n",
      "Einführung                          | True\n",
      "in                                  | True\n",
      "ERP-                                | False\n",
      "und                                 | True\n",
      "CRM-Systeme                         | False\n",
      "mitsamt                             | True\n",
      "Open-Source-Praxisbeispiel          | False\n",
      "\n",
      ">>> ВЫВОД: Как видите, для 'Open-Source-Praxisbeispiel' свойство is_alpha равно False из-за дефисов.\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- Шаг 2: Симуляция логики фильтрации из скрипта ---\n",
      "Собираем слова в список, только если token.is_alpha == True...\n",
      "\n",
      "Результат (уникальные леммы):\n",
      "['anschließend', 'auf', 'beinhalten', 'beschreiben', 'bpmn', 'damit', 'der', 'diagrammsprache', 'ein', 'einführung', 'erhalten', 'es', 'geschäftsprozessanalyse', 'haben', 'in', 'kapitel', 'mitsamt', 'prozessanalyse', 'schluss', 'sich', 'sie', 'teilgebiet', 'und', 'was', 'welcher', 'werden', 'zu', 'zunächst', 'über', 'überblick', 'überhaupt']\n",
      "\n",
      ">>> ВЫВОД: Слово 'open-source-praxisbeispiel' отсутствует в списке, так как оно было отфильтровано.\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- Шаг 3: Решение проблемы - изменяем условие фильтрации ---\n",
      "Собираем слова в список, если token.is_alpha == True ИЛИ в токене есть дефис...\n",
      "\n",
      "Результат с исправленной логикой (уникальные леммы):\n",
      "['anschließend', 'auf', 'beinhalten', 'beschreiben', 'bpmn', 'crm-system', 'damit', 'der', 'diagrammsprache', 'ein', 'einführung', 'erhalten', 'erp', 'es', 'geschäftsprozessanalyse', 'haben', 'in', 'kapitel', 'mitsamt', 'open-source-praxisbeispiel', 'prozessanalyse', 'schluss', 'sich', 'sie', 'teilgebiet', 'und', 'was', 'welcher', 'werden', 'zu', 'zunächst', 'über', 'überblick', 'überhaupt']\n",
      "\n",
      ">>> ВЫВОД: Теперь 'open-source-praxisbeispiel' присутствует в списке!\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- Шаг 4: Как бы сработал German Compound Splitter (GCS) на этом слове ---\n",
      "\n",
      "Разбираем слово: 'Open-Source-Praxisbeispiel'\n",
      "Найденные компоненты:\n",
      "['Open', '-Source', '-Praxis', 'Beispiel']\n",
      "\n",
      ">>> ВЫВОД: GCS успешно разбирает слово на части. Проблема была именно в фильтре ДО вызова GCS.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# playbook_spacy_analysis.py\n",
    "\n",
    "import spacy\n",
    "from contextlib import redirect_stdout\n",
    "import io\n",
    "import os\n",
    "\n",
    "try:\n",
    "    from german_compound_splitter import comp_split\n",
    "    GCS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    GCS_AVAILABLE = False\n",
    "    print(\"Библиотека german-compound-splitter не найдена. Установите ее: pip install german-compound-splitter\")\n",
    "\n",
    "\n",
    "# --- Настройка ---\n",
    "# Загружаем модель spaCy для немецкого языка\n",
    "nlp = spacy.load(\"de_core_news_lg\")\n",
    "\n",
    "# Наш исходный текст\n",
    "text = \"▸ In Kapitel 12, »Geschäftsprozessanalyse«, wird zunächst beschrieben, was es überhaupt damit auf sich hat und welche Teilgebiete die Prozessanalyse beinhaltet. Anschließend erhalten Sie einen Überblick über die Diagrammsprache BPMN und zum Schluss eine Einführung in ERP- und CRM-Systeme mitsamt Open-Source-Praxisbeispiel.\"\n",
    "\n",
    "print(\"--- ИСХОДНЫЙ ТЕКСТ ---\")\n",
    "print(text)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "# --- Шаг 1: Анализ токенизации и свойства `is_alpha` ---\n",
    "# Давайте посмотрим, как spaCy видит каждое слово и что возвращает is_alpha\n",
    "print(\"--- Шаг 1: Анализ токенов и свойства is_alpha ---\")\n",
    "print(f\"{'Токен':<35} | {'is_alpha'}\")\n",
    "print(f\"{'-'*35} | {'-'*10}\")\n",
    "\n",
    "doc = nlp(text)\n",
    "for token in doc:\n",
    "    # Пропускаем знаки препинания и пробелы для наглядности\n",
    "    if not token.is_punct and not token.is_space:\n",
    "        print(f\"{token.text:<35} | {token.is_alpha}\")\n",
    "\n",
    "print(\"\\n>>> ВЫВОД: Как видите, для 'Open-Source-Praxisbeispiel' свойство is_alpha равно False из-за дефисов.\\n\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "# --- Шаг 2: Симуляция логики оригинального скрипта ---\n",
    "# Повторим логику фильтрации из вашего скрипта\n",
    "print(\"--- Шаг 2: Симуляция логики фильтрации из скрипта ---\")\n",
    "print(\"Собираем слова в список, только если token.is_alpha == True...\")\n",
    "\n",
    "lemmas_from_script_logic = []\n",
    "for token in doc:\n",
    "    # ТО САМОЕ УСЛОВИЕ ИЗ ВАШЕГО СКРИПТА\n",
    "    if token.is_alpha and token.dep_ != \"svp\":\n",
    "        # Используем простую лемматизацию для демонстрации\n",
    "        lemmas_from_script_logic.append(token.lemma_)\n",
    "\n",
    "print(\"\\nРезультат (уникальные леммы):\")\n",
    "# Выводим уникальные леммы в нижнем регистре для простоты сравнения\n",
    "print(sorted(list(set([lemma.lower() for lemma in lemmas_from_script_logic]))))\n",
    "print(\"\\n>>> ВЫВОД: Слово 'open-source-praxisbeispiel' отсутствует в списке, так как оно было отфильтровано.\\n\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "# --- Шаг 3: Решение проблемы и проверка ---\n",
    "# Изменим условие, чтобы оно пропускало слова с дефисами\n",
    "print(\"--- Шаг 3: Решение проблемы - изменяем условие фильтрации ---\")\n",
    "print(\"Собираем слова в список, если token.is_alpha == True ИЛИ в токене есть дефис...\")\n",
    "\n",
    "lemmas_with_fix = []\n",
    "for token in doc:\n",
    "    # ИСПРАВЛЕННОЕ УСЛОВИЕ\n",
    "    if (token.is_alpha or '-' in token.text) and token.dep_ != \"svp\":\n",
    "        lemmas_with_fix.append(token.lemma_)\n",
    "\n",
    "print(\"\\nРезультат с исправленной логикой (уникальные леммы):\")\n",
    "print(sorted(list(set([lemma.lower() for lemma in lemmas_with_fix]))))\n",
    "print(\"\\n>>> ВЫВОД: Теперь 'open-source-praxisbeispiel' присутствует в списке!\\n\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "# --- Шаг 4: Демонстрация работы German Compound Splitter (GCS) ---\n",
    "# Теперь покажем, что GCS мог бы разбить это слово, если бы оно не было отфильтровано\n",
    "if GCS_AVAILABLE:\n",
    "    print(\"--- Шаг 4: Как бы сработал German Compound Splitter (GCS) на этом слове ---\")\n",
    "    \n",
    "    word_to_split = \"Open-Source-Praxisbeispiel\"\n",
    "    \n",
    "    # Для GCS нужен словарь. Создадим фиктивный файл, если его нет.\n",
    "    dict_path = \"german.dic\"\n",
    "    if not os.path.exists(dict_path):\n",
    "        print(f\"Словарь '{dict_path}' не найден. Создаю временный с нужными частями.\")\n",
    "        with open(dict_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"Open\\nSource\\nPraxis\\nBeispiel\\n\")\n",
    "\n",
    "    try:\n",
    "        with redirect_stdout(io.StringIO()): # Подавляем лишний вывод GCS\n",
    "             ahocs = comp_split.read_dictionary_from_file(dict_path)\n",
    "        \n",
    "        print(f\"\\nРазбираем слово: '{word_to_split}'\")\n",
    "        \n",
    "        # Подавляем вывод GCS о процессе разбора\n",
    "        with redirect_stdout(io.StringIO()):\n",
    "            dissection = comp_split.dissect(word_to_split, ahocs)\n",
    "        \n",
    "        components = comp_split.merge_fractions(dissection)\n",
    "        \n",
    "        print(\"Найденные компоненты:\")\n",
    "        print(components)\n",
    "        \n",
    "        print(\"\\n>>> ВЫВОД: GCS успешно разбирает слово на части. Проблема была именно в фильтре ДО вызова GCS.\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при работе с GCS: {e}\")\n",
    "    \n",
    "    # Удаляем временный словарь, если мы его создали\n",
    "    # if not os.path.exists(\"german.dic\"):\n",
    "    #     os.remove(dict_path)\n",
    "\n",
    "else:\n",
    "    print(\"--- Шаг 4: GCS недоступен, демонстрация пропущена ---\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac8e820",
   "metadata": {},
   "source": [
    "\n",
    "### Как исправить скрипт?\n",
    "\n",
    "Чтобы ваш скрипт начал обрабатывать такие слова, вам нужно изменить условие. Самый простой способ — разрешить дефисы.\n",
    "\n",
    "Найдите строку (она встречается в нескольких местах):\n",
    "`if token.is_alpha and token.dep_ != \"svp\":`\n",
    "\n",
    "И замените ее на более гибкое условие, например:\n",
    "`if (token.is_alpha or '-' in token.text) and token.dep_ != \"svp\":`\n",
    "\n",
    "Это изменение позволит токенам, содержащим дефис, проходить первоначальный фильтр и попадать в дальнейшую обработку, включая GCS."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "20250825231214-spacy-env (3.9.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
